{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV9c Semantic Segmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMq03DMAJIKQ0Njqq2kdSWO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV9c_Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zhLcYm0f6Pi"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rkuo2000/image-segmentation-keras\n",
        "#%cd image-segmentation-keras"
      ],
      "metadata": {
        "id": "oecBXtL4svZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade keras\n",
        "!pip install tensorflow==2.8"
      ],
      "metadata": {
        "id": "9beczaufpHuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-segmentation"
      ],
      "metadata": {
        "id": "Eh9Yccb1qhP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFwe3m0Lo-kb"
      },
      "source": [
        "# import the necessary packages\n",
        "import numpy as np\n",
        "#import time\n",
        "import cv2\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from six.moves import urllib\n",
        "from matplotlib import gridspec\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUob0sWq4-DK"
      },
      "source": [
        "Semantic segmentation classifies every pixel of the image to one of the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JmCUDpE66hb"
      },
      "source": [
        "# **PSPNet: the model**<br>\n",
        "PSPNet (Pyramid Scene Parsing Network)<br>\n",
        "- **Semantic Segmentation** is to know the category label of each pixels for known objects only.\n",
        "- **Scene Parsing**, which is based on Semantic Segmentation, is to know the category label of ALL pixels within the image.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6kqiFqG7xXc"
      },
      "source": [
        "imageP = cv2.imread(\"/content/cloned-repo/images/sceneParsing.png\")\n",
        "cv2_imshow(imageP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UbwLhUM8Z0a"
      },
      "source": [
        "PSPNet uses global information to parse a scene<br>\n",
        "- **Mismatched Relationship**: FCN predicts the boat in the yellow box as a “car” based on its appearance. But the common knowledge is that a car is seldom over a river.\n",
        "- **Confusion Categories**: FCN predicts the object in the box as part of skyscraper and part of building. These results should be excluded so that the whole object is either skyscraper or building, but not both.\n",
        "-**Inconspicuous Classes**: The pillow has similar appearance with the sheet. Overlooking the global scene category may fail to parse the pillow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3WdRhVt8Uni"
      },
      "source": [
        "imageP = cv2.imread(\"/content/cloned-repo/images/contextAgg.png\")\n",
        "imageP = cv2.resize(imageP, (900,600))\n",
        "cv2_imshow(imageP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7OO9ykr-_kG"
      },
      "source": [
        "**PSPNet in video segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afWzoNpT-mKK"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url=\"https://miro.medium.com/max/1200/1*J33mxWAtCSEV1GsWV3vKLQ.gif\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jqws-r9_J6x"
      },
      "source": [
        "**PSPNet Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqQ_WrP9u1Gx"
      },
      "source": [
        "imageP = cv2.imread(\"/content/cloned-repo/images/pspNet.png\")\n",
        "cv2_imshow(imageP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHN41YSO_N5j"
      },
      "source": [
        "**A example image**\n",
        "This image was taken from a video, it is one of a series of images from the video. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTg_7K_5pLZK"
      },
      "source": [
        "image = cv2.imread(\"/content/cloned-repo/datasetSeg/images_prepped_test/0016E5_07971.png\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX5Bru7E_Sz4"
      },
      "source": [
        "# **Install the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWhu7DDqQfdP"
      },
      "source": [
        "!apt-get install -y libsm6 libxext6 libxrender-dev\n",
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBv9Jvr9QsRw"
      },
      "source": [
        "!pip install keras-segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtaf32RdkoPY"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOosW09mz9_c"
      },
      "source": [
        "# **The datasets**<br>\n",
        "Three different datasets are used to train the same model. <br>\n",
        "This means each of the models - although the same model - will return a different segmentation image. <br>\n",
        "\n",
        "- **pspnet_50_ADE_20K**:  the 20,000-image ADE20K challenge dataset. This ADE20K dataset is a landmark image segmentation dataset, containing a large corpus of both indoor and outdoor images. Every image has an accompanying image segmentation mask dividing the image into 150 different classes pixel-by-pixel.<br>\n",
        "The dataset can be found here: https://groups.csail.mit.edu/vision/datasets/ADE20K/<br>\n",
        "The labels can be found here: https://github.com/CSAILVision/sceneparsing/tree/master/visualizationCode/color150<br>\n",
        "<br>\n",
        "- **psp_101_cityscapres**: this dataset focuses on semantic understanding of urban street scenes. It has 30 classes and 20,000 images <br>\n",
        "The dataset can be found here: https://www.cityscapes-dataset.com/dataset-overview/<br>\n",
        "<br>\n",
        "- **pspnet_101_voc12**: the main goal of the datset is the detection and identification of individual objects from a number of visual object classes in a realistic scene. The data set has 21 classes<br>\n",
        "The class list can be found here: https://github.com/NVIDIA/DIGITS/blob/master/examples/semantic-segmentation/pascal-voc-classes.txt<br>\n",
        "The dataset can be found here: https://deepai.org/dataset/pascal-voc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nt0mdYO_cbu"
      },
      "source": [
        "# **Loading the pretrained models**\n",
        "Three pretrained models PSPNet models are loaded. Each model is trained on a different dataset. <br> The same image is used for each model and a comparison of the outputs is compared. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q3VsHadQyqV"
      },
      "source": [
        "from keras_segmentation.pretrained import pspnet_50_ADE_20K,pspnet_101_cityscapes, pspnet_101_voc12\n",
        "\n",
        "model1 = pspnet_50_ADE_20K() # load the pretrained model trained on ADE20k dataset\n",
        "model2 = pspnet_101_cityscapes() # load the pretrained model trained on Cityscapes dataset\n",
        "model3 = pspnet_101_voc12() # load the pretrained model trained on Pascal VOC 2012 dataset\n",
        "\n",
        "\n",
        "out = model1.predict_segmentation(\n",
        "    inp=image,\n",
        "    out_fname=\"out1.png\"\n",
        ")\n",
        "out2 = model2.predict_segmentation(\n",
        "    inp=image,\n",
        "    out_fname=\"out2.png\"\n",
        ")\n",
        "out3 = model3.predict_segmentation(\n",
        "    inp=image,\n",
        "    out_fname=\"out3.png\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhluov6E_6tb"
      },
      "source": [
        "**A helper function for plotting the images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpWITPz3QaEa"
      },
      "source": [
        "def plotting(image, outSeg):\n",
        "  plt.figure(figsize=(15, 8))\n",
        "  grid_spec = gridspec.GridSpec(1, 3, width_ratios=[6, 6, 6])\n",
        "\n",
        "  plt.subplot(grid_spec[0])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title('input image')\n",
        "\n",
        "  plt.subplot(grid_spec[1])\n",
        "  plt.imshow(outSeg)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation map')\n",
        "\n",
        "  plt.subplot(grid_spec[2])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(outSeg, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation overlay')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut6apgDax5-T"
      },
      "source": [
        "imageO1 = cv2.imread(\"out1.png\")\n",
        "imageO2 = cv2.imread(\"out2.png\")\n",
        "imageO3 = cv2.imread(\"out3.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yleMvvgAAKsX"
      },
      "source": [
        "**The model trained on the ADE20k dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUyQwFdrw9a"
      },
      "source": [
        "plotting(image, imageO1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToUeVFQ6AAHR"
      },
      "source": [
        "**The model trained on the Cityscapes dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCl2Deb2ugyR"
      },
      "source": [
        "plotting(image, imageO2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpnb9Y8DAbgg"
      },
      "source": [
        "**The model trained on the Pascal VOC 2012 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQf-riruuq9m"
      },
      "source": [
        "plotting(image, imageO3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}