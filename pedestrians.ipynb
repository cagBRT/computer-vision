{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pedestrians.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPS5OevSspgrZoVphSL+wSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/pedestrians.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANySGJbf_Ben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -l -s https://github.com/opencv/opencv.git \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXRswFdm_bqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkSSmGAHI_ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAioTOeN94Z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import paths\n",
        "from imutils.object_detection import non_max_suppression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9ugedBMA4f",
        "colab_type": "text"
      },
      "source": [
        "initialize the pedestrian detector. First, we make a call to hog = cv2.HOGDescriptor()  which initializes the Histogram of Oriented Gradients descriptor. Then, we call the setSVMDetector  to set the Support Vector Machine to be pre-trained pedestrian detector, loaded via the cv2.HOGDescriptor_getDefaultPeopleDetector()  function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkkW6LPa-aEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the HOG descriptor/person detector\n",
        "hog = cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGSybcQr_4Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread(\"images/family.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ngxvuYfRWMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagePath = \"images/family.jpg\"\n",
        "image = cv2.imread(imagePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeqQ6MYXMTQD",
        "colab_type": "text"
      },
      "source": [
        "**loading our image off disk and resizing it to have a maximum width of 400 pixels**. The reason we attempt to reduce our image dimensions is two-fold:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCVra1NoMYkA",
        "colab_type": "text"
      },
      "source": [
        "1. **Reducing image size ensures that less sliding windows in the image pyramid need to be evaluated** (i.e., have HOG features extracted from and then passed on to the Linear SVM), thus reducing detection time (and increasing overall detection throughput).<br>\n",
        "2. **Resizing our image also improves the overall accuracy of our pedestrian detection** (i.e., less false-positives)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BecPpoZiG7gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Resize\n",
        "scale_percent = 80 # percent of original size\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "orig = image.copy()\n",
        "# resize image\n",
        "image = cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzHpnEFAYYf8",
        "colab_type": "text"
      },
      "source": [
        "The image should be no more than 400 pixels wide. \n",
        "See the problems caused with this large of an image. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G68b4BjiY37R",
        "colab_type": "text"
      },
      "source": [
        "The winStride  parameter is a 2-tuple that dictates the “step size” in both the x and y location of the sliding window.\n",
        "\n",
        "Both **winStride  and scale  are extremely important parameters that need to be set properly**. These parameter have tremendous implications on not only the accuracy of your detector, but also the speed in which your detector runs.\n",
        "\n",
        "The smaller winStride  is, the more windows need to be evaluated\n",
        "\n",
        "In the context of object detection, a sliding window is a rectangular region of fixed width and height that “slides” across an image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80CPexvbZMq8",
        "colab_type": "text"
      },
      "source": [
        "At each stop of the sliding window (and for each level of the image pyramid, discussed in the scale  section below), we (1) extract HOG features and (2) pass these features on to our Linear SVM for classification. The process of feature extraction and classifier decision is an expensive one, so we would prefer to evaluate as few windows as possible if our intention is to run our Python script in near real-time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPjKtMXTZdbs",
        "colab_type": "text"
      },
      "source": [
        "The padding  parameter is a tuple which indicates the number of pixels in both the x and y direction in which the sliding window ROI is “padded” prior to HOG feature extraction.\n",
        "\n",
        "As suggested by Dalal and Triggs in their 2005 CVPR paper, Histogram of Oriented Gradients for Human Detection, adding a bit of padding surrounding the image ROI prior to HOG feature extraction and classification can actually increase the accuracy of your detector.\n",
        "\n",
        "Typical values for padding include (8, 8), (16, 16), (24, 24), and (32, 32)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz_yJGe1ZikJ",
        "colab_type": "text"
      },
      "source": [
        "This scale  parameter controls the factor in which our image is resized at each layer of the image pyramid, ultimately influencing the number of levels in the image pyramid.\n",
        "\n",
        "A smaller scale  will increase the number of layers in the image pyramid and increase the amount of time it takes to process your image:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSrEFS5NZmrC",
        "colab_type": "text"
      },
      "source": [
        "a larger scale will decrease the number of layers in the pyramid as well as decrease the amount of time it takes to detect objects in an image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umgB_0huZ1ea",
        "colab_type": "text"
      },
      "source": [
        "useMeanShiftGrouping  parameter is a boolean indicating whether or not mean-shift grouping should be performed to handle potential overlapping bounding boxes. This value defaults to False  and in my opinion, should never be set to True  — use non-maxima suppression instead; you’ll get much better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eOrpS5iaDkY",
        "colab_type": "text"
      },
      "source": [
        "To suppress these multiple bounding boxes, Dalal suggested using mean shift (Slide 18). However, in my experience mean shift performs sub-optimally and should not be used as a method of bounding box suppression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt6zwhQNaHoi",
        "colab_type": "text"
      },
      "source": [
        "utilize non-maxima suppression (NMS). Not only is NMS faster, but it obtains much more accurate final detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njjp6PV6SSfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# detect people in the image\n",
        "(rects, weights) = hog.detectMultiScale(image, \n",
        "                                        winStride=(4, 4),\n",
        "                                        padding=(8, 8), \n",
        "                                        scale=1.01)\n",
        "\n",
        "\t# draw the original bounding boxes\n",
        "for (x, y, w, h) in rects:\n",
        "\t\tcv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "\t# apply non-maxima suppression to the bounding boxes using a\n",
        "\t# fairly large overlap threshold to try to maintain overlapping\n",
        "\t# boxes that are still people\n",
        "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
        "pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
        "\t# draw the final bounding boxes\n",
        "for (xA, yA, xB, yB) in pick:\n",
        "\tcv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
        "\t# show some information on the number of bounding boxes\n",
        "filename = imagePath[imagePath.rfind(\"/\") + 1:]\n",
        "print(\"[INFO] {}: {} original boxes, {} after suppression\".format(\n",
        "\t\tfilename, len(rects), len(pick)))\n",
        "\t# show the output images\n",
        "cv2_imshow(orig)\n",
        "cv2_imshow( image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UpYi_iyaR74",
        "colab_type": "text"
      },
      "source": [
        "Tips on speeding up the object detection process\n",
        "Whether you’re batch processing a dataset of images or looking to get your HOG detector to run in real-time (or as close to real-time as feasible), these three tips should help you milk as much performance out of your detector as possible:\n",
        "\n",
        "Resize your image or frame to be as small as possible without sacrificing detection accuracy. Prior to calling the detectMultiScale  function, reduce the width and height of your image. The smaller your image is, the less data there is to process, and thus the detector will run faster.\n",
        "Tune your scale  and winStride  parameters. These two arguments have a tremendous impact on your object detector speed. Both scale  and winStride  should be as large as possible, again, without sacrificing detector accuracy.\n",
        "If your detector still is not fast enough…you might want to look into re-implementing your program in C/C++. Python is great and you can do a lot with it. But sometimes you need the compiled binary speed of C or C++ — this is especially true for resource constrained environments."
      ]
    }
  ]
}