{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV2 ObjectDetection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNk7rtvvO+0GRFXVPboWkVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV2_ObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y01cNuK1Vwvy"
      },
      "source": [
        "# **You Only Look Once (YOLOv3)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVuDX5h9sx5-"
      },
      "source": [
        "Loading the YOLOv3 weights can take about 12 minutes<br> \n",
        "To do this notebook: <br>\n",
        "1. run all\n",
        "2. leave and come back in ~12 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1aRKPFN4hf6"
      },
      "source": [
        "**Clone the repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_p5Y75cp-LD"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOZTP88u4lwF"
      },
      "source": [
        "**Install the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WzetrcyqSNc"
      },
      "source": [
        "!pip3 install opencv-python tensorflow\n",
        "!pip3 install drawbox\n",
        "!pip install --upgrade cvlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CDKJckqlWv"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-hle1B41a_O"
      },
      "source": [
        "# **The YOLOv3 Model**\n",
        "YOLO uses a totally different approach. It applys a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.\n",
        "\n",
        "The model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See this paper for more details on the full system.<br>\n",
        "https://pjreddie.com/darknet/yolo/<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUBkWdT11oK5"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/map50blue.png\", width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9MhGrja0WAJ"
      },
      "source": [
        "**Detect_common_objects**\n",
        "\n",
        "Underneath it uses YOLOv3 model trained on [COCO dataset](https://cocodataset.org/#home) capable of detecting 80 common objects in context.\n",
        "The common objects are:<br>\n",
        "person,\n",
        "bicycle,\n",
        "car,\n",
        "motorcycle,\n",
        "airplane,\n",
        "bus,\n",
        "train,\n",
        "truck,\n",
        "boat,\n",
        "traffic light,\n",
        "fire hydrant,\n",
        "stop sign,\n",
        "parking meter,\n",
        "bench,\n",
        "bird,\n",
        "cat,\n",
        "dog,\n",
        "horse,\n",
        "sheep,\n",
        "cow,\n",
        "elephant,\n",
        "bear,\n",
        "zebra,\n",
        "giraffe,\n",
        "backpack,\n",
        "umbrella,\n",
        "handbag,\n",
        "tie,\n",
        "suitcase,\n",
        "frisbee,\n",
        "skis,\n",
        "snowboard,\n",
        "sports ball,\n",
        "kite,\n",
        "baseball bat,\n",
        "baseball glove,\n",
        "skateboard,\n",
        "surfboard,\n",
        "tennis racket,\n",
        "bottle,\n",
        "wine glass,\n",
        "cup,\n",
        "fork,\n",
        "knife,\n",
        "spoon,\n",
        "bowl,\n",
        "banana,\n",
        "apple,\n",
        "sandwich,\n",
        "orange,\n",
        "broccoli,\n",
        "carrot,\n",
        "hot dog,\n",
        "pizza,\n",
        "donut,\n",
        "cake,\n",
        "chair,\n",
        "couch,\n",
        "potted plant,\n",
        "bed,\n",
        "dining table,\n",
        "toilet,\n",
        "tv,\n",
        "laptop,\n",
        "mouse,\n",
        "remote,\n",
        "keyboard,\n",
        "cell phone,\n",
        "microwave,\n",
        "oven,\n",
        "toaster,\n",
        "sink,\n",
        "refrigerator,\n",
        "book,\n",
        "clock,\n",
        "vase,\n",
        "scissors,\n",
        "teddy bear,\n",
        "hair dryer,\n",
        "toothbrush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQEctb2S2ex"
      },
      "source": [
        "**The image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-loUlLFzqoLz"
      },
      "source": [
        "im = cv2.imread('apple-256261_640.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5bWt7MxS7Wv"
      },
      "source": [
        "**Loading the YOLO model and it's weights**<br>\n",
        "This might take approximately 12 minutes to load and execute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFe_yIfWqECt"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im)\n",
        "output_image = draw_bbox(im, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQwjpwHBTEZ5"
      },
      "source": [
        "**Print the labels the model identifies in the image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2__DdmRjyJBZ"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-veSd7H4TSa6"
      },
      "source": [
        "**Try another image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mKABIThtaWS"
      },
      "source": [
        "im2 = cv2.imread('fruitAndBooks.jpeg')\n",
        "plt.imshow(im2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2s5k3-jtoJy"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im2)\n",
        "output_image2 = draw_bbox(im2, bbox, label, conf)\n",
        "plt.imshow(output_image2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBMT9a6PyNpN"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1OSe86BTdTp"
      },
      "source": [
        "**Try another image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFehGldVt_JJ"
      },
      "source": [
        "im3 = cv2.imread('apple-256261_640UpsideDown.jpg')\n",
        "plt.imshow(im3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3jdXvkGuBZW"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im3)\n",
        "output_image = draw_bbox(im3, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbMNvEVyi8Z"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvABiEwuTi9u"
      },
      "source": [
        "**Antoher image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aR-Hx8Vuh3i"
      },
      "source": [
        "im4 = cv2.imread('/content/cloned-repo/images/apple-and-books-4733-jason-champaigne.jpg')\n",
        "plt.imshow(im4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtiOMmI7up-m"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im4)\n",
        "output_image = draw_bbox(im4, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-W-jXHpx4-5"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_KIxi-tTmdW"
      },
      "source": [
        "**Another image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjx4vd0iu6Ge"
      },
      "source": [
        "im5 = cv2.imread('/content/cloned-repo/images/greenApple.jpg')\n",
        "plt.imshow(im5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXDu4UbvEsi"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im5)\n",
        "output_image = draw_bbox(im5, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGWHQL3kx_1r"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfrqLnvRTpje"
      },
      "source": [
        "**Antoher image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgCeqND3vwzT"
      },
      "source": [
        "im6 = cv2.imread('/content/cloned-repo/images/redApple.jpeg')\n",
        "plt.imshow(im6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyifNpmiv5A2"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im6)\n",
        "output_image = draw_bbox(im6, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FA8_-MYy2Tx"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyQrWtpKTtBG"
      },
      "source": [
        "**Cropped images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE_hCaw7xoK1"
      },
      "source": [
        "im7 = cv2.imread('/content/cloned-repo/images/booksApple.jpg')\n",
        "plt.imshow(im7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVjl0bVxval"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im7)\n",
        "output_image = draw_bbox(im7, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_wyh1_Jy_in"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqiaco5u3kb0"
      },
      "source": [
        "# **Assignment 1**\n",
        "\n",
        "1. Find a photo on the internet - in png or jpg format\n",
        "2. Upload it to the Google CoLab file system\n",
        "3. Use the YOLOv3 pretrained model on the photo\n",
        "4. Print out the labels. How accurate is the model with your photo?\n",
        "5. Can you crop the photo to make it more accurate?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXmf_2ST3_ep"
      },
      "source": [
        "#Assignment 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwUt8ClDKd8o"
      },
      "source": [
        "image = cv2.imread(\"/content/cloned-repo/yolo-object-detection/images/baggage_claim.jpg\")\n",
        "(H, W) = image.shape[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnqWK6a5Kh76"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(image)\n",
        "output_image2 = draw_bbox(image, bbox, label, conf)\n",
        "plt.imshow(output_image2)\n",
        "plt.show()\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjJ_BI26KnDc"
      },
      "source": [
        "import pandas as pd\n",
        "ds1 = pd.Series(bbox)\n",
        "ds2 = pd.Series(conf)\n",
        "ds3 = pd.Series(label)\n",
        "dframe={'boxes':ds1,'confidences': ds2,'classIDs': ds3}\n",
        "df=pd.DataFrame(dframe)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnD7ILuXVNfu"
      },
      "source": [
        "# apply non-maxima suppression to suppress weak, overlapping bounding\n",
        "# boxes\n",
        "idxs = cv2.dnn.NMSBoxes(bbox, conf, .50,0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyvFrmz1ZDP_"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# initialize a list of colors to represent each possible class label\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(label), 3),\n",
        "\tdtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd-47-OnVQ-J"
      },
      "source": [
        "# ensure at least one detection exists\n",
        "if len(idxs) > 0:\n",
        "\t# loop over the indexes we are keeping\n",
        "\tfor i in idxs.flatten():\n",
        "\t\t# extract the bounding box coordinates\n",
        "\t\t(x, y) = (bbox[i][0], bbox[i][1])\n",
        "\t\t(w, h) = (bbox[i][2], bbox[i][3])\n",
        "\t\t# draw a bounding box rectangle and label on the image\n",
        "\t\tcolor = [int(c) for c in COLORS[i]]\n",
        "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "\t\ttext = \"{}: {:.4f}\".format(label[i], conf[i])\n",
        "\t\tcv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t\t0.5, color, 2)\n",
        "# show the output image\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}