{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV2 ObjectDetection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOMWEF6UD0om7oN75FepQgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV2_ObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVuDX5h9sx5-"
      },
      "source": [
        "Loading the YOLOv3 weights can take about 12 minutes<br> \n",
        "To do this notebook: <br>\n",
        "1. run all\n",
        "2. leave and come back in ~12 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_p5Y75cp-LD"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Umg4N213C-"
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"https://github.com/cagBRT/computer-vision.git\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WzetrcyqSNc"
      },
      "source": [
        "!pip3 install opencv-python tensorflow\n",
        "!pip3 install drawbox\n",
        "!pip install --upgrade cvlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CDKJckqlWv"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-loUlLFzqoLz"
      },
      "source": [
        "im = cv2.imread('apple-256261_640.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-hle1B41a_O"
      },
      "source": [
        "# **The YOLO Model**\n",
        "YOLO use a totally different approach. It applys a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.\n",
        "\n",
        "The model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See our paper for more details on the full system.<br>\n",
        "https://pjreddie.com/darknet/yolo/<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUBkWdT11oK5"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/map50blue.png\", width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9MhGrja0WAJ"
      },
      "source": [
        "**Detect_common_objects**\n",
        "\n",
        "Underneath it uses YOLOv3 model trained on COCO dataset capable of detecting 80 common objects in context.\n",
        "The common objects are:<br>\n",
        "person,\n",
        "bicycle,\n",
        "car,\n",
        "motorcycle,\n",
        "airplane,\n",
        "bus,\n",
        "train,\n",
        "truck,\n",
        "boat,\n",
        "traffic light,\n",
        "fire hydrant,\n",
        "stop sign,\n",
        "parking meter,\n",
        "bench,\n",
        "bird,\n",
        "cat,\n",
        "dog,\n",
        "horse,\n",
        "sheep,\n",
        "cow,\n",
        "elephant,\n",
        "bear,\n",
        "zebra,\n",
        "giraffe,\n",
        "backpack,\n",
        "umbrella,\n",
        "handbag,\n",
        "tie,\n",
        "suitcase,\n",
        "frisbee,\n",
        "skis,\n",
        "snowboard,\n",
        "sports ball,\n",
        "kite,\n",
        "baseball bat,\n",
        "baseball glove,\n",
        "skateboard,\n",
        "surfboard,\n",
        "tennis racket,\n",
        "bottle,\n",
        "wine glass,\n",
        "cup,\n",
        "fork,\n",
        "knife,\n",
        "spoon,\n",
        "bowl,\n",
        "banana,\n",
        "apple,\n",
        "sandwich,\n",
        "orange,\n",
        "broccoli,\n",
        "carrot,\n",
        "hot dog,\n",
        "pizza,\n",
        "donut,\n",
        "cake,\n",
        "chair,\n",
        "couch,\n",
        "potted plant,\n",
        "bed,\n",
        "dining table,\n",
        "toilet,\n",
        "tv,\n",
        "laptop,\n",
        "mouse,\n",
        "remote,\n",
        "keyboard,\n",
        "cell phone,\n",
        "microwave,\n",
        "oven,\n",
        "toaster,\n",
        "sink,\n",
        "refrigerator,\n",
        "book,\n",
        "clock,\n",
        "vase,\n",
        "scissors,\n",
        "teddy bear,\n",
        "hair dryer,\n",
        "toothbrush"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFe_yIfWqECt"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im)\n",
        "output_image = draw_bbox(im, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2__DdmRjyJBZ"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mKABIThtaWS"
      },
      "source": [
        "im2 = cv2.imread('fruitAndBooks.jpeg')\n",
        "plt.imshow(im2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2s5k3-jtoJy"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im2)\n",
        "output_image2 = draw_bbox(im2, bbox, label, conf)\n",
        "plt.imshow(output_image2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBMT9a6PyNpN"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFehGldVt_JJ"
      },
      "source": [
        "im3 = cv2.imread('apple-256261_640UpsideDown.jpg')\n",
        "plt.imshow(im3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3jdXvkGuBZW"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im3)\n",
        "output_image = draw_bbox(im3, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbMNvEVyi8Z"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aR-Hx8Vuh3i"
      },
      "source": [
        "im4 = cv2.imread('/content/apple-and-books-4733-jason-champaigne.jpg')\n",
        "plt.imshow(im4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtiOMmI7up-m"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im4)\n",
        "output_image = draw_bbox(im4, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-W-jXHpx4-5"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjx4vd0iu6Ge"
      },
      "source": [
        "im5 = cv2.imread('/content/greenApple.jpg')\n",
        "plt.imshow(im5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXDu4UbvEsi"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im5)\n",
        "output_image = draw_bbox(im5, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGWHQL3kx_1r"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgCeqND3vwzT"
      },
      "source": [
        "im6 = cv2.imread('/content/redApple.jpeg')\n",
        "plt.imshow(im6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyifNpmiv5A2"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im6)\n",
        "output_image = draw_bbox(im6, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FA8_-MYy2Tx"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE_hCaw7xoK1"
      },
      "source": [
        "im7 = cv2.imread('/content/booksApple.jpg')\n",
        "plt.imshow(im7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCVjl0bVxval"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im7)\n",
        "output_image = draw_bbox(im7, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_wyh1_Jy_in"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}