{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV2 ObjectDetection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyObmUYu4lp4XQ/BBz9SqErW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV2_ObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y01cNuK1Vwvy"
      },
      "source": [
        "# **You Only Look Once (YOLOv3)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVuDX5h9sx5-"
      },
      "source": [
        "Loading the YOLOv3 weights can take about 12 minutes<br> \n",
        "To do this notebook: <br>\n",
        "1. run all\n",
        "2. leave and come back in ~12 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1aRKPFN4hf6"
      },
      "source": [
        "**Clone the repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_p5Y75cp-LD"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOZTP88u4lwF"
      },
      "source": [
        "**Install the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WzetrcyqSNc"
      },
      "source": [
        "!pip3 install opencv-python tensorflow\n",
        "!pip3 install drawbox\n",
        "!pip install --upgrade cvlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2CDKJckqlWv"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import cvlib as cv\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-hle1B41a_O"
      },
      "source": [
        "# **The YOLOv3 Model**\n",
        "YOLO uses a totally different approach. It applys a single neural network to the full image. This network divides the image into regions and predicts bounding boxes and probabilities for each region. These bounding boxes are weighted by the predicted probabilities.\n",
        "\n",
        "The model has several advantages over classifier-based systems. It looks at the whole image at test time so its predictions are informed by global context in the image. It also makes predictions with a single network evaluation unlike systems like R-CNN which require thousands for a single image. This makes it extremely fast, more than 1000x faster than R-CNN and 100x faster than Fast R-CNN. See this paper for more details on the full system.<br>\n",
        "https://pjreddie.com/darknet/yolo/<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUBkWdT11oK5"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/map50blue.png\", width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9MhGrja0WAJ"
      },
      "source": [
        "**Detect_common_objects**\n",
        "\n",
        "Underneath it uses YOLOv3 model trained on [COCO dataset](https://cocodataset.org/#home) capable of detecting 80 common objects in context.\n",
        "The common objects are:<br>\n",
        "person,\n",
        "bicycle,\n",
        "car,\n",
        "motorcycle,\n",
        "airplane,\n",
        "bus,\n",
        "train,\n",
        "truck,\n",
        "boat,\n",
        "traffic light,\n",
        "fire hydrant,\n",
        "stop sign,\n",
        "parking meter,\n",
        "bench,\n",
        "bird,\n",
        "cat,\n",
        "dog,\n",
        "horse,\n",
        "sheep,\n",
        "cow,\n",
        "elephant,\n",
        "bear,\n",
        "zebra,\n",
        "giraffe,\n",
        "backpack,\n",
        "umbrella,\n",
        "handbag,\n",
        "tie,\n",
        "suitcase,\n",
        "frisbee,\n",
        "skis,\n",
        "snowboard,\n",
        "sports ball,\n",
        "kite,\n",
        "baseball bat,\n",
        "baseball glove,\n",
        "skateboard,\n",
        "surfboard,\n",
        "tennis racket,\n",
        "bottle,\n",
        "wine glass,\n",
        "cup,\n",
        "fork,\n",
        "knife,\n",
        "spoon,\n",
        "bowl,\n",
        "banana,\n",
        "apple,\n",
        "sandwich,\n",
        "orange,\n",
        "broccoli,\n",
        "carrot,\n",
        "hot dog,\n",
        "pizza,\n",
        "donut,\n",
        "cake,\n",
        "chair,\n",
        "couch,\n",
        "potted plant,\n",
        "bed,\n",
        "dining table,\n",
        "toilet,\n",
        "tv,\n",
        "laptop,\n",
        "mouse,\n",
        "remote,\n",
        "keyboard,\n",
        "cell phone,\n",
        "microwave,\n",
        "oven,\n",
        "toaster,\n",
        "sink,\n",
        "refrigerator,\n",
        "book,\n",
        "clock,\n",
        "vase,\n",
        "scissors,\n",
        "teddy bear,\n",
        "hair dryer,\n",
        "toothbrush"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQEctb2S2ex"
      },
      "source": [
        "**The image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-loUlLFzqoLz"
      },
      "source": [
        "im = cv2.imread('apple-256261_640.jpg')\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5bWt7MxS7Wv"
      },
      "source": [
        "**Loading the YOLO model and it's weights**<br>\n",
        "This might take approximately 12 minutes to load and execute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFe_yIfWqECt"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im)\n",
        "output_image = draw_bbox(im, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQwjpwHBTEZ5"
      },
      "source": [
        "**Print the labels the model identifies in the image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2__DdmRjyJBZ"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-veSd7H4TSa6"
      },
      "source": [
        "**Try another image**<br>\n",
        "This image also have an apple and books in it. <br>\n",
        "But the apple is not detected. Why?<br>\n",
        "The children's blocks and pencils were not identified, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mKABIThtaWS"
      },
      "source": [
        "im2 = cv2.imread('fruitAndBooks.jpeg')\n",
        "plt.imshow(im2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2s5k3-jtoJy"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im2)\n",
        "output_image2 = draw_bbox(im2, bbox, label, conf)\n",
        "plt.imshow(output_image2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBMT9a6PyNpN"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1OSe86BTdTp"
      },
      "source": [
        "**Flip an image upside down**<br>\n",
        "In the first image the books and the apple where identified. <br>\n",
        "What happens when we flip the image upside down?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFehGldVt_JJ"
      },
      "source": [
        "im3 = cv2.imread('apple-256261_640UpsideDown.jpg')\n",
        "plt.imshow(im3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3jdXvkGuBZW"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im3)\n",
        "output_image = draw_bbox(im3, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltbMNvEVyi8Z"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvABiEwuTi9u"
      },
      "source": [
        "**Antoher image**<br>\n",
        "This image has books and an apple. \n",
        "But the labels aren't quite accurate.<br>\n",
        "What is happening here?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aR-Hx8Vuh3i"
      },
      "source": [
        "im4 = cv2.imread('/content/cloned-repo/images/apple-and-books-4733-jason-champaigne.jpg')\n",
        "plt.imshow(im4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtiOMmI7up-m"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im4)\n",
        "output_image = draw_bbox(im4, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-W-jXHpx4-5"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_KIxi-tTmdW"
      },
      "source": [
        "**A Single Apple**<br>\n",
        "How does the YOLO model perform with a single object image?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjx4vd0iu6Ge"
      },
      "source": [
        "im5 = cv2.imread('/content/cloned-repo/images/greenApple.jpg')\n",
        "plt.imshow(im5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXDu4UbvEsi"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im5)\n",
        "output_image = draw_bbox(im5, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGWHQL3kx_1r"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfrqLnvRTpje"
      },
      "source": [
        "**Apple cropped from a previous image**<br>\n",
        "In one of the previous images the YOLO model did not identify the apple. <br>\n",
        "If we crop the image to only show the apple, will the model identify it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgCeqND3vwzT"
      },
      "source": [
        "im6 = cv2.imread('/content/cloned-repo/images/redApple.jpeg')\n",
        "plt.imshow(im6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyifNpmiv5A2"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(im6)\n",
        "output_image = draw_bbox(im6, bbox, label, conf)\n",
        "plt.imshow(output_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FA8_-MYy2Tx"
      },
      "source": [
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swbc5GSRzJwj"
      },
      "source": [
        "**Another image**<br>\n",
        "Create a pandas dataframe of the bounding boxes, the labels, and the confidence of the prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwUt8ClDKd8o"
      },
      "source": [
        "image = cv2.imread(\"/content/cloned-repo/images/dogsOnBeach.jpg\")\n",
        "(H, W) = image.shape[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnqWK6a5Kh76"
      },
      "source": [
        "bbox, label, conf = cv.detect_common_objects(image)\n",
        "output_image2 = draw_bbox(image, bbox, label, conf)\n",
        "plt.imshow(output_image2)\n",
        "plt.show()\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjJ_BI26KnDc"
      },
      "source": [
        "import pandas as pd\n",
        "ds1 = pd.Series(bbox)\n",
        "ds2 = pd.Series(conf)\n",
        "ds3 = pd.Series(label)\n",
        "dframe={'boxes':ds1,'confidences': ds2,'classIDs': ds3}\n",
        "df=pd.DataFrame(dframe)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqiaco5u3kb0"
      },
      "source": [
        "# **Assignment 1**\n",
        "\n",
        "1. Find a photo on the internet - in png or jpg format\n",
        "2. Upload it to the Google CoLab file system\n",
        "3. Use the YOLOv3 pretrained model on the photo\n",
        "4. Print out the labels. How accurate is the model with your photo?\n",
        "5. Can you crop the photo to make it more accurate?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXmf_2ST3_ep"
      },
      "source": [
        "#Assignment 1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}