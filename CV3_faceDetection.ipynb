{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV3  faceDetection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV3_faceDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiUgKSaIC-V"
      },
      "source": [
        "**Object Landmark Detection with Face Detection**<br>\n",
        "Face recognition is an easy task for humans. Experiments have shown, that even one to three day old babies are able to distinguish between known faces. <br>\n",
        "\n",
        "So how hard could it be for a computer? **It is very hard for a computer**\n",
        "\n",
        "It was shown by David Hubel and Torsten Wiesel, that our brain have specialized nerve cells that respond to specific local features of a scene, such as lines, edges, angles or movement. Since we don't see the world as scattered pieces, our visual cortex must somehow combine the different sources of information into useful patterns. <br>\n",
        "\n",
        "*Automatic face recognition is all about extracting those meaningful features from an image, putting them into a useful representation and performing some kind of classification on them.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn9H6zNvIrgG"
      },
      "source": [
        "**Clone the OpenCV git repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgSHNHX2wmEQ"
      },
      "source": [
        "!git clone -l -s https://github.com/opencv/opencv.git \n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZCAm9uMIv_3"
      },
      "source": [
        "**Clone the computer-vision git repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-MQEDw-W0C6"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypj_yYLbW6g1"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxFI_BlWI6Mk"
      },
      "source": [
        "**Using built-in Haar Cascade classifiers on OpenCV**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZPKcZzYYC0N"
      },
      "source": [
        "Use the built-in Haar cascade classifiers in OpenCV. these classifiers have already been pre-trained to recognize faces!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyzNATHoYO-C"
      },
      "source": [
        "These classifiers work by scanning an image from left to right, and top to bottom, at varying scale sizes. Scanning an image from left to right and top to bottom is called the “sliding window” approach.<br>\n",
        "As the window moves from left to right and top to bot- tom, one pixel at a time, the classifier is asked whether or not it “thinks” there is a face in the current window, based on the parameters supplied to the classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9kYOBleYap5"
      },
      "source": [
        "• **scaleFactor**: How much the image size is reduced at each image scale. This value is used to create the scale pyramid in order to detect faces at multiple scales in the image (some faces may be closer to the fore- ground, and thus be larger; other faces may be smaller and in the background, thus the usage of varying scales). A value of 1.05 indicates that Jeremy is re- ducing the size of the image by 5% at each level in the pyramid.<br><br>\n",
        "• **minNeighbors**: How many neighbors each window should have for the area in the window to be consid- ered a face. The cascade classifier will detect multiple windows around a face. This parameter controls how many rectangles (neighbors) need to be detected for the window to be labeled a face.<br><br>\n",
        "• **minSize**: A tuple of width and height (in pixels) in- dicating the minimum size of the window. Bounding boxes smaller than this size are ignored. It is a good idea to start with (30, 30) and fine-tune from there.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMCBpeZRKPwv"
      },
      "source": [
        "**A sample of faces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ikuDgbZZtgH"
      },
      "source": [
        "image = cv2.imread(\"images/face5.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJV_sFWbm6E4"
      },
      "source": [
        "# **Convert the image to grayscale**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBzpOAhXXjdM"
      },
      "source": [
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lzwZad47PVv"
      },
      "source": [
        "The parameters to the cv2.detect-MutliScale function tend to be sensitive, and some parameter choices for one set of images will not work for another set of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNw-Ehss7Yz2"
      },
      "source": [
        "**In most cases, the offending culprit will be the scaleFactor parameter.**<br> \n",
        "In other cases it may be minNeighbors. <br>\n",
        "As a debugging rule, start with the scaleFactor, adjust it as needed, and then move on to minNeighbors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0QU9CSJm-_K"
      },
      "source": [
        "**Use the classifier, equalizerHist, and detectMultiScale to find faces in the grayscale image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30YaH_q5Wv3"
      },
      "source": [
        "# initialize front face classifier\n",
        "cascade = cv2.CascadeClassifier(\n",
        "  \"/content/opencv/data/haarcascades/haarcascade_frontalface_default.xml\")\n",
        "\n",
        "frame = cv2.imread('face.jpeg')\n",
        "\n",
        "# Convert to black-and-white\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blackwhite = cv2.equalizeHist(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXwXAKPXKqVa"
      },
      "source": [
        "**Convert the image using histogram equalization**<br>\n",
        "Basically, the images are modified to cover the full light spectrum. This makes the images appear to be taken under the same lighting conditions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHOGZM8KgXm"
      },
      "source": [
        "cv2_imshow(blackwhite)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12sf7l8RL5to"
      },
      "source": [
        "**Cascade Classifiers**<br>\n",
        "Cascade classifiers are used to detect objects of different sizes in the input image. The detected objects are returned as a list of rectangles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpvU95rgL4F1"
      },
      "source": [
        "rects = cascade.detectMultiScale(blackwhite, \n",
        "                                 scaleFactor=1.1, \n",
        "                                 minNeighbors=3, \n",
        "                                 minSize=(30, 30),\n",
        "                                 flags=cv2.CASCADE_SCALE_IMAGE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4IwSzs6nWeu"
      },
      "source": [
        "**Plot the rectangles on the full color image**\n",
        "The classifier has found faces in the image. The rectangles are drawn around the found objects. <br>\n",
        "Some faces were not detected, why?<br>\n",
        "One face was detected twice, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85X-kEZPvGRr"
      },
      "source": [
        "for (x, y, w, h) in rects:\n",
        "  cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61qj9E-F8upy"
      },
      "source": [
        "While Haar cascades are quite fast and can obtain decent accuracy, they have two prominent shortcomings.\n",
        "\n",
        "**The first is parameter tuning**. You’ll (likely) need to tweak the parameters of the detectMultiScale  function on a per-image basis. This can be a real pain, especially if you are looking to bulk process a dataset of images and cannot manually inspect the output of each face detection.\n",
        "\n",
        "**The second shortcoming** is that Haar cascades can be highly prone to false positives, meaning that faces are detected when there really aren’t any there!\n",
        "\n",
        "Again, this problem can be fixed by tuning the parameters of detectMultiScale  on a case-by-case basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp4iMzEb82Cd"
      },
      "source": [
        "If you find yourself in a situation where either method is not working to your required level of accuracy:\n",
        "\n",
        "**Haar cascades are not giving you your desired level of accuracy**.\n",
        "You need to train your own custom object detector.<br>\n",
        "\n",
        "I would suggest using the HOG + Linear SVM framework, utilizing an image pyramid and sliding windows, you can detect objects in images at various scales and locations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS5CzX3dn7c0"
      },
      "source": [
        "# **Assignment 1**\n",
        "Detect faces in :<br>\n",
        "images/faces3.jpg<br>\n",
        "images/face.jpeg<br>\n",
        "images/faces.jpeg<br>\n",
        "images/faces2.jpeg<br>\n",
        "images/faces4.jpeg<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhB7MFHRng5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RblXcRMnqEk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWyeMfawnuD6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmkSgki_n1vv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWcpTOWxhHR"
      },
      "source": [
        "# **Detect Eyes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORxxatwGskHB"
      },
      "source": [
        "There are two stages in a cascade classifier: <br>detection<br>\n",
        " training. <br><br>\n",
        "OpenCV offers pre-trained classifiers such as eyes, face, and smile. <br>\n",
        "<br>In order to detect, those classifiers, there are XML files associated with the classifiers that must be imported into your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMvaUdGEzlXn"
      },
      "source": [
        "Classifiers which can detect both open and closed eyes include:<br><br>\n",
        "\n",
        "haarcascade_mcs_lefteye.xml<br>\n",
        "haarcascade_mcs_righteye.xml<br>\n",
        "haarcascade_lefteye_2splits.xml<br>\n",
        "haarcascade_righteye_2splits.xml<br><br>\n",
        "Classifiers which can only detect open eyes:<br>\n",
        "\n",
        "haarcascade_eye.xml<br>\n",
        "haarcascade_eye_tree_eyeglasses.xml<br><br>\n",
        "\n",
        "The difference between haarcascade_eye.xml and haarcascade_eye_tree_eyeglasses.xml is <br>\n",
        ">haarcascade_eye_tree_eyeglasses.xml can detect the eyes if the person is wearing glasses, but is not reliable if they do not wear glasses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJcOOPAnwFgt"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_eye.xml')\n",
        "eyeglasses_cascade = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_eye_tree_eyeglasses.xml')\n",
        "smile_cascade = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_smile.xml')\n",
        "upperbody_cascade = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_upperbody.xml')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgv9P0tXNIjg"
      },
      "source": [
        "USing different cascade classifiers, see if the model does better at detecting faces. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr3cDs6kp1uJ"
      },
      "source": [
        "img = cv2.imread(\"images/faces2.jpg\")\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAjedBSerRQS"
      },
      "source": [
        "blackwhite = cv2.equalizeHist(gray)\n",
        "\n",
        "rects = cascade.detectMultiScale(blackwhite, \n",
        "                                 scaleFactor=1.1, \n",
        "                                 minNeighbors=3, \n",
        "                                 minSize=(30, 30),\n",
        "                                 flags=cv2.CASCADE_SCALE_IMAGE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGDIDy5OsFRJ"
      },
      "source": [
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        " \n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    roi_gray = gray[y:y+h, x:x+w]\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    eyes = smile_cascade.detectMultiScale(roi_gray)\n",
        "    for (ex,ey,ew,eh) in eyes:\n",
        "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST9DHZ_SxEPu"
      },
      "source": [
        "for (x, y, w, h) in rects:\n",
        "  cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hrZGu0Nz7jY"
      },
      "source": [
        "# **Assignment 2**\n",
        "Use at least one of the cascadeClassifiers to detect a facial feature in images/faces2.jpg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSPO-4Cm0PPT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}