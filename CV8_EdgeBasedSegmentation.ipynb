{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV8 EdgeBasedSegmentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNQof9DnoiNZgmDqXFqZRdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/computer-vision/blob/master/CV8_EdgeBasedSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpLhaE45hQNC"
      },
      "source": [
        "from skimage.color import rgb2gray\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import ndimage\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYLvmdfbntZ"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/computer-vision.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWjqvvV3O4G1"
      },
      "source": [
        "What divides two objects in an image? There is always an edge between two adjacent regions with different grayscale values (pixel values). The edges can be considered as the discontinuous local features of an image.<br>\n",
        "\n",
        "We can make use of this discontinuity to detect edges and hence define a boundary of the object. This helps us in detecting the shapes of multiple objects present in a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tjFUPRga-bu"
      },
      "source": [
        "Using convolution we can detect the edges of objects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqbtoP6teadL"
      },
      "source": [
        "image = cv2.imread(\"images/convolution.png\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zdw2P86a54A"
      },
      "source": [
        "image = cv2.imread(\"/content/sobelFilters.png\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAnxOhBGgRTZ"
      },
      "source": [
        "image = cv2.imread(\"/content/kernelConvolution.png\")\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-8nGvf8gc1L"
      },
      "source": [
        "This Kernel Convolution is an example of an X Direction Kernel usage. If an image were scanning from left to write, we can see that if the filter was set at (2,2) in the image above, it would have a value of 400 and therefore would have a fairly prominent edge at that point. If a user wanted to exaggerate the edge, then the user would need to change the filter values of -2 and 2 to higher magnitude. Perhaps -5 and 5. This would make the gradient of the edge larger and therefore, more noticeable.\n",
        "\n",
        "Once the image is processed in the X direction, we can then process the image in the Y direction. Magnitudes of both the X and Y kernels will then be added together to produce a final image showing all edges in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmYgElE8goSz"
      },
      "source": [
        "The first step to using Sobel Edge Detection is to convert the image to grayscale. While it is possible to use the algorithm in standard RGB scale, it is easier to implement in a grayscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIZF3nx7g3oG"
      },
      "source": [
        "image = plt.imread('/content/index.png')\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erUJKu50hJae"
      },
      "source": [
        "# converting to grayscale\n",
        "gray = rgb2gray(image)\n",
        "\n",
        "# defining the sobel filters\n",
        "sobel_horizontal = np.array([np.array([1, 2, 1]), np.array([0, 0, 0]), np.array([-1, -2, -1])])\n",
        "print(sobel_horizontal, 'is a kernel for detecting horizontal edges\\n')\n",
        " \n",
        "sobel_vertical = np.array([np.array([-1, 0, 1]), np.array([-2, 0, 2]), np.array([-1, 0, 1])])\n",
        "print(sobel_vertical, 'is a kernel for detecting vertical edges')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoIqDvpThZUH"
      },
      "source": [
        "out_h = ndimage.convolve(gray, sobel_horizontal, mode='reflect')\n",
        "out_v = ndimage.convolve(gray, sobel_vertical, mode='reflect')\n",
        "# here mode determines how the input array is extended when the filter overlaps a border."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kT0q9VEhcSQ"
      },
      "source": [
        "plt.imshow(out_h, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTMzsrTPhfBe"
      },
      "source": [
        "plt.imshow(out_v, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeKkYbYDhkuf"
      },
      "source": [
        "Here, we are able to identify the horizontal as well as the vertical edges. There is one more type of filter that can detect both horizontal and vertical edges at the same time. This is called the laplace operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUMpnm29h_vL"
      },
      "source": [
        "kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
        "print(kernel_laplace, 'is a laplacian kernel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzgI5xO3iCiN"
      },
      "source": [
        "out_l = ndimage.convolve(gray, kernel_laplace, mode='reflect')\n",
        "plt.imshow(out_l, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6qsCW2TiGiu"
      },
      "source": [
        "# **Assignment**\n",
        "Use the above methods to detect edges in:<br>\n",
        " /content/cloned-repo/images/dogsOnBeach.jpg\n",
        "\n",
        "1. Modify the center value of the Laplacian kernel to see the changes in the detection of the edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwjb9QZ0iYhC"
      },
      "source": [
        "#Assignment\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}